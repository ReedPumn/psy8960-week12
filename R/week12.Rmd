---
title: "PSY 8960: Week 12 Project"
author: "Reed Priest"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
---

## Script Settings and Resources

```{r Set wd and load packages}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(tidyverse)
library(RedditExtractoR)
library(tm)
library(qdap)
library(textstem)
library(RWeka)
library(doParallel)
library(ldatuning)
library(topicmodels)
library(tidytext)
library(wordcloud)
```

## Data Import and Cleaning
```{r}
# The last approach I used trying to scrape Reddit data using fromJSON produced the same issues from before with page scrolling. So after some Chat GPTing, I found the RedditExtractoR package. It downloaded all the data I needed using this code, but it took about 15 minutes to do so. This package isn't part of the course materials, but it was an effective solution. See this page for details: https://github.com/ivan-rivera/RedditExtractor.

 #reddit_urls <- find_thread_urls(subreddit = "IOPsychology", sort_by = "new", period = "year")
# reddit_content <- get_thread_content(reddit_urls$url)
# week12_tbl <- as_tibble(reddit_content$threads) %>%
  # select(title = title, upvotes = upvotes)
# write_csv(week12_tbl, file = "../data/week12data.csv")
week12_tbl <- read_csv(file = "../data/week12data.csv")
```

```{r Corpus setup}
io_corpus_original <- VCorpus(VectorSource(week12_tbl$title))
io_corpus_trimmed <- io_corpus_original %>%
  tm_map(content_transformer(replace_abbreviation)) %>%
  tm_map(content_transformer(replace_contraction)) %>%
  tm_map(content_transformer(str_to_lower)) %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(removeWords, c(stopwords("en"), "io psychology")) %>%
  tm_map(stripWhitespace) %>%
  tm_map(content_transformer(lemmatize_words)) %>%
  # Even after removing io-relevant stopwords, empty cases still exist. So we remove them with this function
  tm_filter(FUN = function(x) {
    return(nchar(stripWhitespace(x$content)[[1]]) > 1)
  })
```

```{r Comparing corpuses}
compare_them <- function(corpus_origingal, corpus_trimmed) {
  possible <- 1:length(io_corpus_original)
  chosen <- sample(possible, 1)
  compare <- list("Original" = content(io_corpus_original[[chosen]]), "Comparison" = content(io_corpus_trimmed[[chosen]]))
  return(compare)
}
replicate(20, compare_them())
```

```{r Create DTMs}
tokenizer <- function(x) {
  NGramTokenizer(x, Weka_control(min = 1, max = 2))
}
io_dtm <- DocumentTermMatrix(io_corpus_trimmed, control = list(tokenize = tokenizer))
# All sparse terms are eliminated with this sparse argument value.
io_slim_dtm <- removeSparseTerms(io_dtm, .997)
# These lines of code calculate our n:k ratio. I played with the numbers a bit, and setting teh sparse argument in the above line to .997 is the first value that reached our desired n:k threshold.
n <- length(io_corpus_trimmed)
k <- ncol(io_slim_dtm)
n/k


# This identifies which indices in our DTM are blank. I tried to preprocess softly to prevent problems here.
io_dtm_tbl <- tibble(totals = rowSums(test), as_tibble(io_corpus_original))
# Opening this tibble and using the arrow keys to sort the "totals" column, we find there are two missing data points. They coincide with doc_ids 487 and 737. To remove these entries, I went back and used the code provided on the Canvas page.
```


## Analysis
```{r Categorizing posgts}
# I am using paralellized processing to speed up this part of analyses. If you are running these analyses on a computer with less than 8 cores, you may want to not run this code.
num_clusters <- makeCluster(7)
registerDoParallel(num_clusters)
lda_tuning <- FindTopicsNumber(io_dtm, topics = seq(5, 20, by = 1), metrics = c( "Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"), verbose = TRUE)
FindTopicsNumber_plot(lda_tuning)
stopCluster(num_clusters)
registerDoSEQ()
# It seems like 10 topics exist in our data.
```

```{r Analyzing categories}
lda_results <- LDA(io_dtm, 10)
lda_betas <- tidy(lda_results, matrix = "beta")
lda_gammas <- tidy(lda_results, matrix = "gamma")
# This series of pipes produces the top words in each category. It's very helpful to see what topics each category focuses on.
betas <- lda_betas %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  arrange(topic, -beta)

# This series of pipes does a similar procedure for our gamma values with documents.
gammas <- lda_gammas %>%
  group_by(document) %>%
  top_n(1, gamma) %>%
  slice(1) %>%
  ungroup %>%
  mutate(document = as.numeric(document)) %>%
  arrange(document)

# This series of lines creates our week12_tbl. We first create two tibbles with ids to enable joining.
week12_tbl_with_ids <- week12_tbl %>%
  mutate(doc_id = as.character(1:nrow(week12_tbl)))
topics_tbl_with_ids <- tibble(doc_id = Docs(io_dtm))
# We then create the tibble with the four columns we desire.
week12_tbl <- topics_tbl_with_ids %>%
  left_join(y = week12_tbl_with_ids) %>%
  mutate(original = title,
         topic = gammas$topic,
         probability = gammas$gamma) %>%
  select(-title, -upvotes)
```

```{r Interpretations}
# Q1: Using the beta matrix alone, what topics would you conclude your final topic list maps onto? (e.g., topic 1, 2, 3â€¦n each reflect what substantive topic construct? Use your best judgment.)
# A1: From the previous topic plots, I chose 10 topics. I labeled these topics as follows: 1) career searching, 2) disseminating content, 3) professional development, 4) career development, 5) I-O functions, 6) seeking advice, 7) training programs, 8) general I-O psychology, 9) analysis, and 10) graduate school.

# Q2: Look at the original text of documents with the highest and lowest probabilities assigned to each document. Do your topic names derived from your interpretation of the beta matrix conceptually match with the content of the original posts? What kind of validity evidence does your answer to this question represent?
# A2: No, each topic does not have a perfectly clean set of indices in which the highest probabilities clearly represent the given topic. At best, about half of the documents within a given topic "hang around" the same title for that topic. As a result, an argument could be made to choose less topics. The process of exploring possible themes in our data resembles factorial validity, particularly through exploratory factor analysis.
```